# -*- coding: utf-8 -*-
"""binary_xboost_lightdm.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ip24RrC8hVuTOF83vhRz_fm01OHCAdtN
"""

# pip install lightgbm==3.3.5

import xgboost as xgb
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# 데이터 로드
data = load_breast_cancer()
X = data.data
y = data.target

# 데이터셋 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# XGBoost 모델 설정
model = xgb.XGBClassifier(objective='binary:logistic', colsample_bytree=0.3, learning_rate=0.1,
                          max_depth=5, alpha=10, n_estimators=10)

# 모델 학습
model.fit(X_train, y_train)

# 예측
y_pred = model.predict(X_test)

# 평가
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy: %.2f%%" % (accuracy * 100.0))
print(confusion_matrix(y_test, y_pred))
print(classification_report(y_test, y_pred))



import lightgbm as lgb
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

data = load_breast_cancer()
X = data.data
y = data.target

# 데이터셋 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# LightGBM 데이터셋 생성
train_dataset = lgb.Dataset(X_train, label=y_train)
test_dataset = lgb.Dataset(X_test, label=y_test, reference=train_dataset)


## CODE
params = {
    'boosting_type': 'gbdt', # Gradient Boosting Decision Tree
    'objective': 'binary', # 이진 분류
    'metric': 'binary_logloss', # 평가 지표
    'num_leaves': 31, # 한 트리가 가질 수 있는 최대 리프 수
    'learning_rate': 0.05, # 학습률
    'feature_fraction': 0.9, # 트리를 생성할 때마다 선택할 피처의 비율
    'bagging_fraction': 0.8, # 데이터를 샘플링하는 비율
    'bagging_freq': 5 # k회 반복마다 배깅을 수행
}

# 모델 학습
gbm = lgb.train(params,
                train_dataset,
                num_boost_round=100, # 부스팅 반복 횟수
                valid_sets=test_dataset, # 평가 데이터셋
                early_stopping_rounds=10) # 조기 종료 조건


# 예측
y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)

# # 성능 평가 (예: AUC 점수 계산)
# from sklearn.metrics import roc_auc_score
# auc_score = roc_auc_score(y_test, y_pred)
# print(f'Test AUC score: {auc_score}')

# # 평가
y_pred_labels = (y_pred > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred_labels)
print("Accuracy: %.2f%%" % (accuracy * 100.0))
print(confusion_matrix(y_test, y_pred_labels))
print(classification_report(y_test, y_pred_labels))

print(y_test.shape)
print(y_pred.shape)

y_pred_labels = (y_pred > 0.5).astype(int)
accuracy = accuracy_score(y_test, y_pred_labels)
print("Accuracy: %.2f%%" % (accuracy * 100.0))
print(confusion_matrix(y_test, y_pred_labels))
print(classification_report(y_test, y_pred_labels))

